{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# tf.enable_eager_execution()\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tf.app.flags.DEFINE_integer('virtule_RoiHeight', 32, '')\n",
    "# # tf.app.flags.DEFINE_integer('virtule_MaxRoiWidth', 256, '')\n",
    "# # FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# class RoiRotate(object):\n",
    "# \tdef __init__(self, features, features_stride):\n",
    "# \t\tself.features = features\n",
    "# \t\tself.features_stride = features_stride\n",
    "\n",
    "# \t\tself.max_RoiWidth = 256 / features_stride\n",
    "# \t\tself.fix_RoiHeight = 32 / features_stride\n",
    "# \t\tself.ratio = float(self.fix_RoiHeight) / self.max_RoiWidth\n",
    "\n",
    "# \tdef scanFunc(self,state=0,b_input=0):\n",
    "# \t\tifeatures, outBox, cropBox, angle = b_input\n",
    "# \t\tcropFeatures = tf.image.crop_to_bounding_box(ifeatures, outBox[1], outBox[0], outBox[3], outBox[2])\n",
    "# \t\tprint(angle)\n",
    "# \t\tprint(cropFeatures.shape)\n",
    "# \t\trotateCropedFeatures = cropFeatures#tf.contrib.image.rotate(cropFeatures, angle)\n",
    "\n",
    "# \t\ttextImgFeatures = tf.image.crop_to_bounding_box(rotateCropedFeatures, cropBox[1], cropBox[0], cropBox[3], cropBox[2])\n",
    "\n",
    "# \t\t# resize keep ratio \t\n",
    "# \t\tw = tf.cast(tf.ceil(tf.multiply(tf.divide(self.fix_RoiHeight, cropBox[3]), tf.cast(cropBox[2], tf.float64))), tf.int32)\n",
    "# \t\tresize_textImgFeatures = tf.image.resize_images(textImgFeatures, (self.fix_RoiHeight, w), 1)\n",
    "# \t\tw = tf.minimum(w, self.max_RoiWidth)\n",
    "# \t\tpad_or_crop_textImgFeatures = tf.image.crop_to_bounding_box(resize_textImgFeatures, 0, 0, self.fix_RoiHeight, w)\n",
    "# \t\t# pad\n",
    "# # \t\tpad_or_crop_textImgFeatures = tf.image.pad_to_bounding_box(pad_or_crop_textImgFeatures, 0, 0, self.fix_RoiHeight, self.max_RoiWidth)\n",
    "\t\t\n",
    "# \t\treturn [pad_or_crop_textImgFeatures, w]\n",
    "\n",
    "\n",
    "# \tdef __call__(self, brboxes, expand_w=20):\n",
    "# \t\tpaddings = tf.constant([[0, 0],[expand_w, expand_w], [expand_w, expand_w], [0, 0]])\n",
    "# \t\tfeatures_pad = tf.pad(self.features, paddings, \"CONSTANT\")\n",
    "# \t\tfeatures_pad = tf.expand_dims(features_pad, axis=1)\n",
    "# \t\t# features_pad shape: [b, 1, h, w, c]\n",
    "# \t\tnums = features_pad.shape[0]\n",
    "# \t\tchannels = features_pad.shape[-1]\n",
    "\n",
    "# \t\tbtextImgFeatures = []\n",
    "# \t\tws = []\n",
    "\n",
    "# \t\tfor b, rboxes in enumerate(brboxes):\n",
    "# \t\t\toutBoxes, cropBoxes, angles = rboxes\n",
    "# \t\t\t# outBoxes = tf.cast(tf.ceil(tf.divide(outBoxes, self.features_stride)), tf.int32)  # float div\n",
    "# \t\t\t# cropBoxes = tf.cast(tf.ceil(tf.divide(cropBoxes, self.features_stride)), tf.int32) # float div\n",
    "\n",
    "# \t\t\toutBoxes = tf.div(outBoxes, self.features_stride)  # int div\n",
    "# \t\t\tcropBoxes = tf.div(cropBoxes, self.features_stride) # int div\n",
    "\n",
    "# \t\t\toutBoxes_xy = outBoxes[:, :2]\n",
    "# \t\t\toutBoxes_xy =  tf.add(outBoxes_xy, expand_w)\n",
    "# \t\t\toutBoxes = tf.concat([outBoxes_xy, outBoxes[:, 2:]], axis=1)\n",
    "\n",
    "# \t\t\t# len_crop = outBoxes.shape[0]  # error tf.stack cannot convert an unknown Dimension to a tensor: ?\n",
    "# \t\t\tlen_crop = tf.shape(outBoxes)[0]\n",
    "# \t\t\tifeatures_pad = features_pad[b]\n",
    "# \t\t\t# ifeatures_tile = tf.tile(ifeatures_pad, tf.stack([len_crop, 1, 1, 1]))\n",
    "# \t\t\tifeatures_tile = tf.tile(ifeatures_pad, [len_crop, 1, 1, 1])\n",
    "# \t\t\tprint(ifeatures_tile.shape)\n",
    "# \t\t\tfor idx,features in enumerate(ifeatures_tile):\n",
    "# \t\t\t\tb_input = (features,outBoxes[idx],cropBoxes[idx],angles[idx])\n",
    "# \t\t\t\ttextImgFeatures = self.scanFunc(b_input = b_input)\n",
    "# \t\t\t\tprint(textImgFeatures[0].shape)\n",
    "# \t\t\t\tbtextImgFeatures.append(tf.expand_dims(textImgFeatures[0],axis=0))\n",
    "# \t\t\t\tws.append(textImgFeatures[1])\n",
    "# # \t\t\ttextImgFeatures = tf.scan(self.scanFunc, [ifeatures_tile, outBoxes, cropBoxes, angles], [np.zeros((self.fix_RoiHeight, self.max_RoiWidth, channels), np.float32), np.array(0, np.float32)])\n",
    "\n",
    "\n",
    "# \t\tbtextImgFeatures = tf.concat(btextImgFeatures, axis=0)\n",
    "# # \t\tws = tf.concat(ws, axis=0)\n",
    "\n",
    "# \t\treturn btextImgFeatures, ws\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.int32(1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.app.flags.DEFINE_integer('virtule_RoiHeight', 32, '')\n",
    "# tf.app.flags.DEFINE_integer('virtule_MaxRoiWidth', 256, '')\n",
    "# FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "class RoiRotate(object):\n",
    "\tdef __init__(self, features, features_stride):\n",
    "\t\tself.features = features\n",
    "\t\tself.features_stride = features_stride\n",
    "\n",
    "\t\tself.max_RoiWidth = np.int32(256 / features_stride)\n",
    "\t\tself.fix_RoiHeight = np.int32(32 / features_stride)\n",
    "\t\tself.ratio = float(self.fix_RoiHeight) / self.max_RoiWidth\n",
    "\n",
    "\tdef scanFunc(self,b_input=0):\n",
    "\t\tangle = 0\n",
    "\t\tifeatures, outBox, cropBox = b_input\n",
    "\t\tprint(ifeatures.shape)\n",
    "\t\tprint(outBox.shape)\n",
    "\t\tprint(cropBox.shape)\n",
    "\t\tprint(angle)\n",
    "\t\tcropFeatures = tf.image.crop_to_bounding_box(ifeatures, outBox[1], outBox[0], outBox[3], outBox[2])\n",
    "\t\t\n",
    "\t\tprint(cropFeatures.shape)\n",
    "\t\trotateCropedFeatures = cropFeatures#tf.contrib.image.rotate(cropFeatures, angle)\n",
    "\n",
    "\t\ttextImgFeatures = tf.image.crop_to_bounding_box(rotateCropedFeatures, cropBox[1], cropBox[0], cropBox[3], cropBox[2])\n",
    "        \n",
    "\t\t# resize keep ratio \t\n",
    "\t\tcnt1 = tf.divide(self.fix_RoiHeight,cropBox[3])\n",
    "\t\tprint(cnt1.dtype)\n",
    "# \t\tw = tf.cast(tf.ceil(tf.multiply(cnt1,1.0*cropBox[2])),tf.int32)\n",
    "\t\tw = tf.cast(tf.ceil(tf.multiply(cnt1,tf.cast(cropBox[2],tf.float64))),tf.int32)\n",
    "\t\tprint(w.dtype)\n",
    "\t\tresize_textImgFeatures = tf.image.resize_images(textImgFeatures, (self.fix_RoiHeight, w), 1)\n",
    "        \n",
    "\t\tw = tf.minimum(w, self.max_RoiWidth)\n",
    "        \n",
    "\t\tpad_or_crop_textImgFeatures = tf.image.crop_to_bounding_box(resize_textImgFeatures, 0, 0, self.fix_RoiHeight, w)\n",
    "\t\t# pad\n",
    "# \t\tpad_or_crop_textImgFeatures = tf.image.pad_to_bounding_box(pad_or_crop_textImgFeatures, 0, 0, self.fix_RoiHeight, self.max_RoiWidth)\n",
    "\t\tprint(\"ok\")\n",
    "\t\treturn [pad_or_crop_textImgFeatures, w]\n",
    "\n",
    "\n",
    "\tdef __call__(self, brboxes, expand_w=20):\n",
    "\t\tpaddings = tf.constant([[0, 0],[expand_w, expand_w], [expand_w, expand_w], [0, 0]])\n",
    "\t\tfeatures_pad = tf.pad(self.features, paddings, \"CONSTANT\")\n",
    "\t\tfeatures_pad = tf.expand_dims(features_pad, axis=1)\n",
    "\t\t# features_pad shape: [b, 1, h, w, c]\n",
    "\t\tnums = features_pad.shape[0]\n",
    "\t\tchannels = features_pad.shape[-1]\n",
    "\n",
    "\t\tbtextImgFeatures = []\n",
    "\t\tws = []\n",
    "\n",
    "\t\tfor b, rboxes in enumerate(brboxes):\n",
    "\t\t\toutBoxes, cropBoxes, angles = rboxes\n",
    "\t\t\t# outBoxes = tf.cast(tf.ceil(tf.divide(outBoxes, self.features_stride)), tf.int32)  # float div\n",
    "\t\t\t# cropBoxes = tf.cast(tf.ceil(tf.divide(cropBoxes, self.features_stride)), tf.int32) # float div\n",
    "\n",
    "\t\t\toutBoxes = tf.div(outBoxes, self.features_stride)  # int div\n",
    "\t\t\tcropBoxes = tf.div(cropBoxes, self.features_stride) # int div\n",
    "\n",
    "\t\t\toutBoxes_xy = outBoxes[:, :2]\n",
    "\t\t\toutBoxes_xy =  tf.add(outBoxes_xy, expand_w)\n",
    "\t\t\toutBoxes = tf.concat([outBoxes_xy, outBoxes[:, 2:]], axis=1)\n",
    "\n",
    "\t\t\t# len_crop = outBoxes.shape[0]  # error tf.stack cannot convert an unknown Dimension to a tensor: ?\n",
    "\t\t\tlen_crop = tf.shape(outBoxes)[0]\n",
    "\t\t\tifeatures_pad = features_pad[b]\n",
    "\t\t\t# ifeatures_tile = tf.tile(ifeatures_pad, tf.stack([len_crop, 1, 1, 1]))\n",
    "\t\t\tifeatures_tile = tf.tile(ifeatures_pad, [len_crop, 1, 1, 1])\n",
    "\t\t\tprint(ifeatures_tile.shape)\n",
    "# \t\t\tfor idx,features in enumerate(ifeatures_tile):\n",
    "# \t\t\t\tb_input = (features,outBoxes[idx],cropBoxes[idx],angles[idx])\n",
    "# \t\t\t\ttextImgFeatures = self.scanFunc(b_input = b_input)\n",
    "# \t\t\t\tprint(textImgFeatures[0].shape)\n",
    "# \t\t\t\tbtextImgFeatures.append(tf.expand_dims(textImgFeatures[0],axis=0))\n",
    "# \t\t\t\tws.append(textImgFeatures[1])\n",
    "\t\t\ttextImgFeatures = tf.map_fn(lambda x:self.scanFunc(x), (ifeatures_tile, outBoxes, cropBoxes))\n",
    "\t\t\tbtextImgFeatures.append(textImgFeatures[0])\n",
    "\t\t\tws.append(textImgFeatures[1])\n",
    "            \n",
    "\t\tbtextImgFeatures = tf.concat(btextImgFeatures, axis=0)\n",
    "# \t\tws = tf.concat(ws, axis=0)\n",
    "\n",
    "\t\treturn btextImgFeatures, ws\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = np.random.random((2,56,56,9))\n",
    "features.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "brboxes = [(np.array([[4,4,50,50],[4,4,50,50]],dtype=np.int32),\n",
    "            np.array([[4,4,10,10],[4,4,10,10]],dtype=np.int32),\n",
    "            np.array([[0],[0]],dtype=np.float32))]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 96, 96, 9)\n",
      "(96, 96, 9)\n",
      "(4,)\n",
      "(4,)\n",
      "0\n",
      "(?, ?, 9)\n",
      "<dtype: 'float64'>\n",
      "<dtype: 'int32'>\n",
      "ok\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "The two structures don't have the same nested structure.\n\nFirst structure: type=tuple str=(tf.float64, tf.int32, tf.int32)\n\nSecond structure: type=list str=[<tf.Tensor 'map_26/while/crop_to_bounding_box_2/Squeeze:0' shape=(16, ?, 9) dtype=float64>, <tf.Tensor 'map_26/while/Minimum:0' shape=() dtype=int32>]\n\nMore specifically: The two namedtuples don't have the same sequence type. First structure type=tuple str=(tf.float64, tf.int32, tf.int32) has type tuple, while second structure type=list str=[<tf.Tensor 'map_26/while/crop_to_bounding_box_2/Squeeze:0' shape=(16, ?, 9) dtype=float64>, <tf.Tensor 'map_26/while/Minimum:0' shape=() dtype=int32>] has type list\nEntire first structure:\n(., ., .)\nEntire second structure:\n[., .]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types)\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0m_pywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssertSameStructure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnest2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=tuple str=(tf.float64, tf.int32, tf.int32)\n\nSecond structure: type=list str=[<tf.Tensor 'map_26/while/crop_to_bounding_box_2/Squeeze:0' shape=(16, ?, 9) dtype=float64>, <tf.Tensor 'map_26/while/Minimum:0' shape=() dtype=int32>]\n\nMore specifically: The two namedtuples don't have the same sequence type. First structure type=tuple str=(tf.float64, tf.int32, tf.int32) has type tuple, while second structure type=list str=[<tf.Tensor 'map_26/while/crop_to_bounding_box_2/Squeeze:0' shape=(16, ?, 9) dtype=float64>, <tf.Tensor 'map_26/while/Minimum:0' shape=() dtype=int32>] has type list",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-63273059846c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmyroi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRoiRotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrboxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-c03bff7a98e6>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, brboxes, expand_w)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m#                               btextImgFeatures.append(tf.expand_dims(textImgFeatures[0],axis=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m#                               ws.append(textImgFeatures[1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                         \u001b[0mtextImgFeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscanFunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mifeatures_tile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutBoxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcropBoxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                         \u001b[0mbtextImgFeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextImgFeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                         \u001b[0mws\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtextImgFeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         maximum_iterations=n)\n\u001b[0m\u001b[1;32m    495\u001b[0m     \u001b[0mresults_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3289\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3290\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3291\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3292\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3293\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   3002\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 3004\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   3005\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2937\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m   2938\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2939\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2940\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3258\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3259\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3260\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(i, tas)\u001b[0m\n\u001b[1;32m    482\u001b[0m       \u001b[0mpacked_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_ta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem_ta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems_ta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m       \u001b[0mpacked_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m       \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m       \u001b[0mflat_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0mtas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types)\u001b[0m\n\u001b[1;32m    184\u001b[0m                   \u001b[0;34m\"Entire first structure:\\n%s\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                   \u001b[0;34m\"Entire second structure:\\n%s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                   % (str(e), str1, str2))\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=tuple str=(tf.float64, tf.int32, tf.int32)\n\nSecond structure: type=list str=[<tf.Tensor 'map_26/while/crop_to_bounding_box_2/Squeeze:0' shape=(16, ?, 9) dtype=float64>, <tf.Tensor 'map_26/while/Minimum:0' shape=() dtype=int32>]\n\nMore specifically: The two namedtuples don't have the same sequence type. First structure type=tuple str=(tf.float64, tf.int32, tf.int32) has type tuple, while second structure type=list str=[<tf.Tensor 'map_26/while/crop_to_bounding_box_2/Squeeze:0' shape=(16, ?, 9) dtype=float64>, <tf.Tensor 'map_26/while/Minimum:0' shape=() dtype=int32>] has type list\nEntire first structure:\n(., ., .)\nEntire second structure:\n[., .]"
     ]
    }
   ],
   "source": [
    "myroi = RoiRotate(features,2)(brboxes)\n",
    "\n",
    "b = (features[0],np.random.random((4)),np.random.random((1)),np.random.random((4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(4), Dimension(16), Dimension(16), Dimension(9)])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myroi[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=6590, shape=(4, 16, 16, 9), dtype=float64, numpy=\n",
       "array([[[[0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         ...,\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728]],\n",
       "\n",
       "        [[0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         ...,\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728]],\n",
       "\n",
       "        [[0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         ...,\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         ...,\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629]],\n",
       "\n",
       "        [[0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         ...,\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629]],\n",
       "\n",
       "        [[0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         ...,\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629]]],\n",
       "\n",
       "\n",
       "       [[[0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         ...,\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728]],\n",
       "\n",
       "        [[0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         ...,\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728]],\n",
       "\n",
       "        [[0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         [0.07087115, 0.82283827, 0.89725548, ..., 0.0774242 ,\n",
       "          0.09105242, 0.2413881 ],\n",
       "         ...,\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728],\n",
       "         [0.53907062, 0.18065589, 0.2359692 , ..., 0.65722372,\n",
       "          0.77801394, 0.58936728]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         ...,\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629]],\n",
       "\n",
       "        [[0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         ...,\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629]],\n",
       "\n",
       "        [[0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         [0.06525075, 0.5991528 , 0.20126971, ..., 0.07854465,\n",
       "          0.74621894, 0.67717224],\n",
       "         ...,\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629],\n",
       "         [0.47208423, 0.97101306, 0.02249253, ..., 0.00749056,\n",
       "          0.4147364 , 0.85341629]]],\n",
       "\n",
       "\n",
       "       [[[0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         ...,\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527]],\n",
       "\n",
       "        [[0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         ...,\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527]],\n",
       "\n",
       "        [[0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         ...,\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         ...,\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104]],\n",
       "\n",
       "        [[0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         ...,\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104]],\n",
       "\n",
       "        [[0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         ...,\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104]]],\n",
       "\n",
       "\n",
       "       [[[0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         ...,\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527]],\n",
       "\n",
       "        [[0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         ...,\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527]],\n",
       "\n",
       "        [[0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         [0.95535742, 0.26929801, 0.8102429 , ..., 0.86084617,\n",
       "          0.10035271, 0.61687156],\n",
       "         ...,\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527],\n",
       "         [0.09139039, 0.90797935, 0.06561963, ..., 0.56918371,\n",
       "          0.30069428, 0.60780527]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         ...,\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104]],\n",
       "\n",
       "        [[0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         ...,\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104]],\n",
       "\n",
       "        [[0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         [0.39553682, 0.58227483, 0.59923393, ..., 0.19655326,\n",
       "          0.65310121, 0.03700204],\n",
       "         ...,\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104],\n",
       "         [0.98038972, 0.64655011, 0.63234645, ..., 0.84440504,\n",
       "          0.65129868, 0.14664104]]]])>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myroi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function map_fn in module tensorflow.python.ops.functional_ops:\n",
      "\n",
      "map_fn(fn, elems, dtype=None, parallel_iterations=None, back_prop=True, swap_memory=False, infer_shape=True, name=None)\n",
      "    map on the list of tensors unpacked from `elems` on dimension 0.\n",
      "    \n",
      "    The simplest version of `map_fn` repeatedly applies the callable `fn` to a\n",
      "    sequence of elements from first to last. The elements are made of the\n",
      "    tensors unpacked from `elems`. `dtype` is the data type of the return\n",
      "    value of `fn`. Users must provide `dtype` if it is different from\n",
      "    the data type of `elems`.\n",
      "    \n",
      "    Suppose that `elems` is unpacked into `values`, a list of tensors. The shape\n",
      "    of the result tensor is `[values.shape[0]] + fn(values[0]).shape`.\n",
      "    \n",
      "    This method also allows multi-arity `elems` and output of `fn`.  If `elems`\n",
      "    is a (possibly nested) list or tuple of tensors, then each of these tensors\n",
      "    must have a matching first (unpack) dimension.  The signature of `fn` may\n",
      "    match the structure of `elems`.  That is, if `elems` is\n",
      "    `(t1, [t2, t3, [t4, t5]])`, then an appropriate signature for `fn` is:\n",
      "    `fn = lambda (t1, [t2, t3, [t4, t5]]):`.\n",
      "    \n",
      "    Furthermore, `fn` may emit a different structure than its input.  For example,\n",
      "    `fn` may look like: `fn = lambda t1: return (t1 + 1, t1 - 1)`.  In this case,\n",
      "    the `dtype` parameter is not optional: `dtype` must be a type or (possibly\n",
      "    nested) tuple of types matching the output of `fn`.\n",
      "    \n",
      "    To apply a functional operation to the nonzero elements of a SparseTensor\n",
      "    one of the following methods is recommended. First, if the function is\n",
      "    expressible as TensorFlow ops, use\n",
      "    \n",
      "    ```python\n",
      "      result = SparseTensor(input.indices, fn(input.values), input.dense_shape)\n",
      "    ```\n",
      "    \n",
      "    If, however, the function is not expressible as a TensorFlow op, then use\n",
      "    \n",
      "    ```python\n",
      "    result = SparseTensor(\n",
      "      input.indices, map_fn(fn, input.values), input.dense_shape)\n",
      "    ```\n",
      "    \n",
      "    instead.\n",
      "    \n",
      "    When executing eagerly, map_fn does not execute in parallel even if\n",
      "    `parallel_iterations` is set to a value > 1. You can still get the\n",
      "    performance benefits of running a function in parallel by using the\n",
      "    `tf.contrib.eager.defun` decorator,\n",
      "    \n",
      "    ```python\n",
      "    # Assume the function being used in map_fn is fn.\n",
      "    # To ensure map_fn calls fn in parallel, use the defun decorator.\n",
      "    @tf.contrib.eager.defun\n",
      "    def func(tensor):\n",
      "      return tf.map_fn(fn, tensor)\n",
      "    ```\n",
      "    \n",
      "    Note that if you use the defun decorator, any non-TensorFlow Python code\n",
      "    that you may have written in your function won't get executed. See\n",
      "    `tf.contrib.eager.defun` for more details. The recommendation would be to\n",
      "    debug without defun but switch to defun to get performance benefits of\n",
      "    running map_fn in parallel.\n",
      "    \n",
      "    Args:\n",
      "      fn: The callable to be performed.  It accepts one argument, which will\n",
      "        have the same (possibly nested) structure as `elems`.  Its output\n",
      "        must have the same structure as `dtype` if one is provided, otherwise\n",
      "        it must have the same structure as `elems`.\n",
      "      elems: A tensor or (possibly nested) sequence of tensors, each of which\n",
      "        will be unpacked along their first dimension.  The nested sequence\n",
      "        of the resulting slices will be applied to `fn`.\n",
      "      dtype: (optional) The output type(s) of `fn`.  If `fn` returns a structure\n",
      "        of Tensors differing from the structure of `elems`, then `dtype` is not\n",
      "        optional and must have the same structure as the output of `fn`.\n",
      "      parallel_iterations: (optional) The number of iterations allowed to run\n",
      "        in parallel. When graph building, the default value is 10. While executing\n",
      "        eagerly, the default value is set to 1.\n",
      "      back_prop: (optional) True enables support for back propagation.\n",
      "      swap_memory: (optional) True enables GPU-CPU memory swapping.\n",
      "      infer_shape: (optional) False disables tests for consistent output shapes.\n",
      "      name: (optional) Name prefix for the returned tensors.\n",
      "    \n",
      "    Returns:\n",
      "      A tensor or (possibly nested) sequence of tensors.  Each tensor packs the\n",
      "      results of applying `fn` to tensors unpacked from `elems` along the first\n",
      "      dimension, from first to last.\n",
      "    \n",
      "    Raises:\n",
      "      TypeError: if `fn` is not callable or the structure of the output of\n",
      "        `fn` and `dtype` do not match, or if elems is a SparseTensor.\n",
      "      ValueError: if the lengths of the output of `fn` and `dtype` do not match.\n",
      "    \n",
      "    Examples:\n",
      "      ```python\n",
      "      elems = np.array([1, 2, 3, 4, 5, 6])\n",
      "      squares = map_fn(lambda x: x * x, elems)\n",
      "      # squares == [1, 4, 9, 16, 25, 36]\n",
      "      ```\n",
      "    \n",
      "      ```python\n",
      "      elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\n",
      "      alternate = map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)\n",
      "      # alternate == [-1, 2, -3]\n",
      "      ```\n",
      "    \n",
      "      ```python\n",
      "      elems = np.array([1, 2, 3])\n",
      "      alternates = map_fn(lambda x: (x, -x), elems, dtype=(tf.int64, tf.int64))\n",
      "      # alternates[0] == [1, 2, 3]\n",
      "      # alternates[1] == [-1, -2, -3]\n",
      "      ```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.map_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"tuple\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-608621409f64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"tuple\") to list"
     ]
    }
   ],
   "source": [
    "[5]+(1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function randint:\n",
      "\n",
      "randint(...) method of mtrand.RandomState instance\n",
      "    randint(low, high=None, size=None, dtype='l')\n",
      "    \n",
      "    Return random integers from `low` (inclusive) to `high` (exclusive).\n",
      "    \n",
      "    Return random integers from the \"discrete uniform\" distribution of\n",
      "    the specified dtype in the \"half-open\" interval [`low`, `high`). If\n",
      "    `high` is None (the default), then results are from [0, `low`).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    low : int\n",
      "        Lowest (signed) integer to be drawn from the distribution (unless\n",
      "        ``high=None``, in which case this parameter is one above the\n",
      "        *highest* such integer).\n",
      "    high : int, optional\n",
      "        If provided, one above the largest (signed) integer to be drawn\n",
      "        from the distribution (see above for behavior if ``high=None``).\n",
      "    size : int or tuple of ints, optional\n",
      "        Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "        ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "        single value is returned.\n",
      "    dtype : dtype, optional\n",
      "        Desired dtype of the result. All dtypes are determined by their\n",
      "        name, i.e., 'int64', 'int', etc, so byteorder is not available\n",
      "        and a specific precision may have different C types depending\n",
      "        on the platform. The default value is 'np.int'.\n",
      "    \n",
      "        .. versionadded:: 1.11.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    out : int or ndarray of ints\n",
      "        `size`-shaped array of random integers from the appropriate\n",
      "        distribution, or a single such random int if `size` not provided.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    random.random_integers : similar to `randint`, only for the closed\n",
      "        interval [`low`, `high`], and 1 is the lowest value if `high` is\n",
      "        omitted. In particular, this other one is the one to use to generate\n",
      "        uniformly distributed discrete non-integers.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.random.randint(2, size=10)\n",
      "    array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0])\n",
      "    >>> np.random.randint(1, size=10)\n",
      "    array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "    \n",
      "    Generate a 2 x 4 array of ints between 0 and 4, inclusive:\n",
      "    \n",
      "    >>> np.random.randint(5, size=(2, 4))\n",
      "    array([[4, 0, 2, 1],\n",
      "           [3, 2, 2, 0]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.random.randint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 6, 9, 9],\n",
       "       [7, 4, 4, 8],\n",
       "       [6, 9, 9, 6]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(10,size=(3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60576446, 0.52387257, 0.99469501])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random((3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function rotate in module tensorflow.contrib.image.python.ops.image_ops:\n",
      "\n",
      "rotate(images, angles, interpolation='NEAREST', name=None)\n",
      "    Rotate image(s) counterclockwise by the passed angle(s) in radians.\n",
      "    \n",
      "    Args:\n",
      "      images: A tensor of shape (num_images, num_rows, num_columns, num_channels)\n",
      "         (NHWC), (num_rows, num_columns, num_channels) (HWC), or\n",
      "         (num_rows, num_columns) (HW). The rank must be statically known (the\n",
      "         shape is not `TensorShape(None)`.\n",
      "      angles: A scalar angle to rotate all images by, or (if images has rank 4)\n",
      "         a vector of length num_images, with an angle for each image in the batch.\n",
      "      interpolation: Interpolation mode. Supported values: \"NEAREST\", \"BILINEAR\".\n",
      "      name: The name of the op.\n",
      "    \n",
      "    Returns:\n",
      "      Image(s) with the same type and shape as `images`, rotated by the given\n",
      "      angle(s). Empty space due to the rotation will be filled with zeros.\n",
      "    \n",
      "    Raises:\n",
      "      TypeError: If `image` is an invalid type.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.contrib.image.rotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function pad_to_bounding_box in module tensorflow.python.ops.image_ops_impl:\n",
      "\n",
      "pad_to_bounding_box(image, offset_height, offset_width, target_height, target_width)\n",
      "    Pad `image` with zeros to the specified `height` and `width`.\n",
      "    \n",
      "    Adds `offset_height` rows of zeros on top, `offset_width` columns of\n",
      "    zeros on the left, and then pads the image on the bottom and right\n",
      "    with zeros until it has dimensions `target_height`, `target_width`.\n",
      "    \n",
      "    This op does nothing if `offset_*` is zero and the image already has size\n",
      "    `target_height` by `target_width`.\n",
      "    \n",
      "    Args:\n",
      "      image: 4-D Tensor of shape `[batch, height, width, channels]` or\n",
      "             3-D Tensor of shape `[height, width, channels]`.\n",
      "      offset_height: Number of rows of zeros to add on top.\n",
      "      offset_width: Number of columns of zeros to add on the left.\n",
      "      target_height: Height of output image.\n",
      "      target_width: Width of output image.\n",
      "    \n",
      "    Returns:\n",
      "      If `image` was 4-D, a 4-D float Tensor of shape\n",
      "      `[batch, target_height, target_width, channels]`\n",
      "      If `image` was 3-D, a 3-D float Tensor of shape\n",
      "      `[target_height, target_width, channels]`\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If the shape of `image` is incompatible with the `offset_*` or\n",
      "        `target_*` arguments, or either `offset_height` or `offset_width` is\n",
      "        negative.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.image.pad_to_bounding_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(tf.keras.Model):\n",
    "    def __init__(self): \n",
    "        super(MNISTModel, self).__init__() \n",
    "        self.dense1 = tf.keras.layers.Dense(units=10) \n",
    "        self.dense2 = tf.keras.layers.Dense(units=10) \n",
    "    def call(self, input): \n",
    "        \"\"\"Run the model.\"\"\" \n",
    "        result = self.dense1(input) \n",
    "        result = self.dense2(result) \n",
    "        result = self.dense2(result) \n",
    "        # reuse variables from dense2 layer return result \n",
    "model = MNISTModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.build(input_shape=(None,100))\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has never been called, thus its weights have not yet been created, so no summary can be displayed. Build the model first (e.g. by calling it on some data).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   1635\u001b[0m     \"\"\"\n\u001b[1;32m   1636\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1637\u001b[0;31m       raise ValueError('This model has never been called, thus its weights '\n\u001b[0m\u001b[1;32m   1638\u001b[0m                        \u001b[0;34m'have not yet been created, so no summary can be '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m                        \u001b[0;34m'displayed. Build the model first '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has never been called, thus its weights have not yet been created, so no summary can be displayed. Build the model first (e.g. by calling it on some data)."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A layer's `call` method should return a Tensor or a list of Tensors, not None (layer: mnist_model_3).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-5dda7dd9b813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n\u001b[1;32m    761\u001b[0m                            \u001b[0;34m'or a list of Tensors, not None (layer: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m                            self.name + ').')\n\u001b[0m\u001b[1;32m    763\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;31m# Deferred mode behavior: use `compute_output_shape` to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A layer's `call` method should return a Tensor or a list of Tensors, not None (layer: mnist_model_3)."
     ]
    }
   ],
   "source": [
    "batch = tf.constant(np.random.random(size=(10,100)),dtype=tf.float32)\n",
    "model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 784)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "A layer's `call` method should return a Tensor or a list of Tensors, not None (layer: mnist_model_6).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-91f6788b5149>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# => (1, 1, 784)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.12/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n\u001b[1;32m    761\u001b[0m                            \u001b[0;34m'or a list of Tensors, not None (layer: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m                            self.name + ').')\n\u001b[0m\u001b[1;32m    763\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;31m# Deferred mode behavior: use `compute_output_shape` to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: A layer's `call` method should return a Tensor or a list of Tensors, not None (layer: mnist_model_6)."
     ]
    }
   ],
   "source": [
    "batch = tf.zeros([1, 1, 784])\n",
    "print(batch.shape)  # => (1, 1, 784)\n",
    "\n",
    "result = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "elems = (np.array([1, 2, 3]), np.array([-1, 1, -1]))\n",
    "alternate = tf.map_fn(lambda x: x[0] * x[1], elems, dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mul_2:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(tf.multiply(1.0,2),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function div in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "div(x, y, name=None)\n",
      "    Divides x / y elementwise (using Python 2 division operator semantics).\n",
      "    \n",
      "    NOTE: Prefer using the Tensor division operator or tf.divide which obey Python\n",
      "    division operator semantics.\n",
      "    \n",
      "    This function divides `x` and `y`, forcing Python 2.7 semantics. That is,\n",
      "    if one of `x` or `y` is a float, then the result will be a float.\n",
      "    Otherwise, the output will be an integer type. Flooring semantics are used\n",
      "    for integer division.\n",
      "    \n",
      "    Args:\n",
      "      x: `Tensor` numerator of real numeric type.\n",
      "      y: `Tensor` denominator of real numeric type.\n",
      "      name: A name for the operation (optional).\n",
      "    Returns:\n",
      "      `x / y` returns the quotient of x and y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function divide in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "divide(x, y, name=None)\n",
      "    Computes Python style division of `x` by `y`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.divide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function multiply in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "multiply(x, y, name=None)\n",
      "    Returns x * y element-wise.\n",
      "    \n",
      "    *NOTE*: ``tf.multiply`` supports broadcasting. More about broadcasting\n",
      "    [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
      "    \n",
      "    Args:\n",
      "      x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
      "      y: A `Tensor`. Must have the same type as `x`.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `x`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Mul_6:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.multiply(2.0,1.0*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
